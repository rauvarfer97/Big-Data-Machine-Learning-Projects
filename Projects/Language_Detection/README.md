# Multilingual Text Classification: A Machine Learning Approach for Language Detection

## Project Overview
This project focuses on **Multilingual Text Classification**, applying **machine learning** techniques for **language detection and analysis**. The task of language identification is essential as many additional NLP tasks, such as lexical analysis, depend on it. The project involves **data preparation, model evaluation, and comparison**.

---

## Data Source
The dataset used in this project is the **European Parliament Proceedings Parallel Corpus 1996-2011**, available at:  
ðŸ”— [https://www.statmt.org/europarl/](https://www.statmt.org/europarl/)  

Due to its large size, the dataset has **not been included** in this repository but can be downloaded from the link above. The corpus consists of European Parliament session transcripts in **German, Spanish, French, English, Italian, and Polish**.

---

## Project Contents
- **Jupyter Notebook (`NLP_Project.ipynb`)**:
  - Loads and preprocesses the multilingual dataset.
  - Performs **text vectorization** using NLP techniques.
  - Applies **classification models** for language detection.
  - Evaluates model performance using different metrics.

---

## Required Libraries
To execute the notebook, install the following dependencies:

```python
pip install pandas numpy scikit-learn nltk
```

Or, if using Jupyter Notebook:

```python
!pip install pandas numpy scikit-learn nltk
```

---

## Usage
1. Download the dataset from the provided link.
2. Place the dataset files in an appropriate directory.
3. Open and execute **`NLP_Project.ipynb`** in Jupyter Notebook.
4. Analyze model results and evaluate language classification accuracy.

---

## Author
**RaÃºl Varela Ferrando**

