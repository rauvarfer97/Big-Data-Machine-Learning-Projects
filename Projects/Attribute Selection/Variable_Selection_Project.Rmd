---
title: "Analysis and Evaluation of Variable Selection Techniques for Classification Models"
author: "Ra√∫l Varela Ferrando"
output:
  html_document:
    df_print: paged
  pdf_document: default
always_allow_html: yes
---

<div class=text-justify>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r paquetes, include=FALSE}
library(tidyverse)
library(tinytex)
library(readxl)
library(caret)
library(ROCR)
library(kernlab)
library(FSelector)
library(mlbench)
library(klaR)
library(catdata)
```

#### Perform the following actions on the database used by each student in the Machine Learning I assignment on the topic of Probabilistic Classification.

#### Perform a train/test split (75% and 25%). The variable selection procedures will be applied to the train set and evaluated on the test set.

Before starting, it should be noted that we modified the data within RStudio to remove the id variable, which only served as an identifier for each observation. The variable to study will be *Empleado*, which represents whether the person is employed (1) or not (0), and our predictor variables will be the remaining ones.

First, we load our data, standardizing the numerical variables so that they share the same mean and standard deviation.

```{r DataLoad}
data0 = read_excel('score_test.xlsx')[,-1]
var.num = c(2:8)
data = as.data.frame(scale(data0[,var.num]))
data$Empleado = as.factor(data0$Empleado)
```

Once the data is loaded, we proceed to partition it into the training and test sets.

```{r Partitioning}
set.seed(1735791)
ind_train = createDataPartition(data$Empleado, p=0.75, list=FALSE)
data_train = data[ind_train,]
data_test = data[-ind_train,]
```

#### For the train data, use two univariate filters from the Fselector library to determine the two most relevant attributes in each filter.

Since no specific filters are mentioned, I will use the  **oneR()** filter and the **information.gain()** filter based on entropy.

```{r 3}
pesos_oneR = oneR(Empleado ~ .,data_train)
cutoff.k(pesos_oneR,2)
```


```{r 4}
pesos_infgain = information.gain(Empleado ~ .,data_train)
cutoff.k(pesos_infgain,2)
```
According to these two filters, the most important attributes for describing the response variable Empleado are Tiempo_empleo and Saldo_cuenta, which make sense considering that these variables represent the duration of employment and the balance in the person's bank account, as their names suggest.

#### 3. Apply and evaluate two variable selection techniques for a classification model using Fisher's Linear Discriminant Analysis or logistic regression.

Since we want to apply and evaluate the techniques using linear discriminant analysis, we will use the klaR library. First, we begin with the **stepclass()** function, which by default applies an algorithm in both directions, **backward** and **forward**, meaning it evaluates models starting from one with all variables and vice versa. We choose **Accuracy** as the criterion, and the algorithm will return a model when the improvement over previous models is not greater than 1%.

```{r StepWise}
set.seed(1735791)
lda_stepw <- stepclass(Empleado ~ ., data = data_train, 
                       method = "lda", 
                       improvement=0.01,
                       criterion = "AC")

lda_stepw
str(lda_stepw)
```
As observed, under this algorithm, we obtained a model with only one variable, **Tiempo_empleo**. Next, we will build our final model and see if it correctly predicts the values in the test set.

```{r resultadosStepW}
lda_stepw$process
plot(lda_stepw$process[,4],type="l",lwd=2,
     ylab="Tasa de acierto VC")

lda_stepw$model

lda_SW=lda(lda_stepw$formula, data = data_train)
lda_SW
```

```{r EvalStepW1}
preditestSW= predict(lda_SW,data_test)
str(preditestSW)

confutestSW= table(Real=data_test$Empleado, Pred=preditestSW$class)
confutestSW
100*diag(prop.table(confutestSW,1))
100*sum(diag(prop.table(confutestSW)))
```

```{r EvalStepW2}
rocSW<- roc(data_test$Empleado,preditestSW$posterior[,2])
rocSW

plot(rocSW,col="red",lwd=2,
     main="ROC test")
```

As observed from the confusion matrix, our model has a good accuracy rate due to the large number of employees in the dataset, but it classifies all cases as 1, i.e., employed, so our classifier is not functioning correctly. This is an issue that also occurred in the previous MLI assignment, which is due to the chosen dataset.
Now, we will use the **greedy.wilks()** function, which is based on the Wilks' Lambda criterion. It starts with the variable that separates the largest number of classes and adds variables if the associated p-value that minimizes the Lambda criterion is lower than the specified threshold.

```{r GW}
criterio_GW <- greedy.wilks(Empleado ~ ., data = data_train,
                            niveau = 0.05)
criterio_GW

lda_GW=lda(criterio_GW$formula, data = data_train)
lda_GW
```

```{r EvalGW}
preditestGW= predict(lda_GW,data_test)
str(preditestGW)

confutestGW= table(Real=data_test$Empleado, Pred=preditestGW$class)
confutestGW
100*diag(prop.table(confutestGW,1))
100*sum(diag(prop.table(confutestGW)))
```


```{r EvalGW2}
rocGW<- roc(data_test$Empleado,preditestGW$posterior[,2])
rocGW


plot(rocGW,col="red",lwd=2,
     main="ROC test")
```

We obtain a similar result to the previous one, but to demonstrate that this is due to the chosen dataset, I tested the same algorithms with several datasets, for example, the "heart" dataset from the **catdata** library. This dataset contains 462 observations of 10 variables, of which we will study the y variable, which represents whether or not the person has coronary heart disease.

```{r Particionamiento2}
set.seed(1735791)
data("heart")
data=as.data.frame(heart)
data$y=as.factor(data$y)
data$famhist=as.factor(data$famhist)
ind_train = createDataPartition(data$y, p=0.75, list=FALSE)
data_train = data[ind_train,]
data_test = data[-ind_train,]
```

```{r StepWise2}
set.seed(1735791)
lda_stepw <- stepclass(y ~ ., data = data_train, 
                       method = "lda", 
                       improvement=0.01,
                       criterion = "AC")

lda_stepw
str(lda_stepw)
```


```{r resultadosStepW2}
lda_stepw$process
plot(lda_stepw$process[,4],type="l",lwd=2,
     ylab="Tasa de acierto VC")

lda_stepw$model

lda_SW=lda(lda_stepw$formula, data = data_train)
lda_SW
```

As observed, we do not obtain a very high accuracy rate.

```{r EvalStepW1.1}
preditestSW= predict(lda_SW,data_test)
str(preditestSW)

confutestSW= table(Real=data_test$y, Pred=preditestSW$class)
confutestSW
100*diag(prop.table(confutestSW,1))
100*sum(diag(prop.table(confutestSW)))
```
According to our confusion matrix, we can see that 88% of the cases where the person does not have the disease and 37.5% of the cases where the person does have the disease are correctly classified, meaning the classifier is not very good overall. However, we demonstrated that the issue in the previous case was due to the chosen dataset.

```{r EvalStepW1.2}
rocSW<- roc(data_test$y,preditestSW$posterior[,2])
rocSW

plot(rocSW,col="red",lwd=2,
     main="ROC test")
```

Finally, I will evaluate the **greedy.wilks()** algorithm on this dataset.

```{r GW2}
criterio_GW <- greedy.wilks(y ~ ., data = data_train,
                            niveau = 0.05)
criterio_GW

lda_GW=lda(y ~age + ldl + famhist + tobacco, data = data_train)
lda_GW
```

```{r EvalGW2.1}
preditestGW= predict(lda_GW,data_test)
str(preditestGW)

confutestGW= table(Real=data_test$y, Pred=preditestGW$class)
confutestGW
100*diag(prop.table(confutestGW,1))
100*sum(diag(prop.table(confutestGW)))
```


```{r EvalGW2.2}
rocGW<- roc(data_test$y,preditestGW$posterior[,2])
rocGW


plot(rocGW,col="red",lwd=2,
     main="ROC test")
```


In this case, we improve the result slightly compared to the **Step Wise** algorithm, although we still do not obtain a good classification for the cases with the disease. However, I found this classification more interesting than the previous one.